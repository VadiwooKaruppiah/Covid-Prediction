---
title: "covid-baseModels"
author: "Vadiwoo Karuppiah"
date: "6/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

 



library(tidyverse)
library(dplyr)
library(ggplot2)
library(corrplot)
library(ggthemes)
library(DT)
library(tidyverse)
library(ggcorrplot)
library(caret)
library(rlang)
library(FSelector)
library(FactoMineR)
library(rpart.plot)
library(ROCR)

```
## VIEW OF RAW DATA 
```{r,view raw data}
mysubset <- read.csv("covid_cleanData.csv")
dim(mysubset)
str(mysubset)
mysubset$HealthStatus = as.factor(mysubset$HealthStatus)
mysubset$gender = as.factor(mysubset$gender)

mysubset$chronic_disease_binary = as.factor(mysubset$chronic_disease_binary)
mysubset$chronic_disease_1 = as.factor(mysubset$chronic_disease_1)
mysubset$main_symptom = as.factor(mysubset$main_symptom)
mysubset$AgeGroup = as.factor(mysubset$AgeGroup)
dim(mysubset)
str(mysubset)
```
## Data Splitting
```{r, Data splitting}
## Data Splitting


datasample <- sample(2, nrow(mysubset), replace=TRUE,prob = c(0.7,0.3))

traindata <- mysubset[datasample==1,]
testdata <- mysubset[datasample==2,]
dim(traindata)
dim(testdata)

```

## DECISION TREE
```{r, Decision Tree}

#Loading libraries
library(rpart.plot)
library(caret)
op <- options(digits.secs=6)

ptm <- proc.time() 
dt_model <-rpart(formula = HealthStatus~ ., data = traindata,  method = "class")
proc.time() - ptm
object.size(dt_model)
typeof(dt_model)
names(dt_model)
print(dt_model)
varImp(dt_model) 
dt_model$variable.importance


fit <- rpart(HealthStatus~., data = traindata, method = 'class')
rpart.plot(fit, extra = 106)

library(pROC)
probsTrain <- predict(dt_model, traindata, type = "prob")



# Predicting Status on Train Data
# prediction trainData}
predict_status_train <-predict(fit, traindata, type = 'class')
table_mat_train <- table(traindata$HealthStatus, predict_status_train)
table_mat_train

## Predicting Status on Test Data
#  prediction testData}
predict_status_test <-predict(fit, testdata, type = 'class')
table_mat_test <- table(testdata$HealthStatus, predict_status_test)
table_mat_test


## Performance Measurement on Train Data
# traindata Accuracy}
accuracy_Train <- sum(diag(table_mat_train)) / sum(table_mat_train)
print(paste('Accuracy for train', accuracy_Train))


## Performance Measurement on Test Data
# testData Accuracy}
accuracy_Test <- sum(diag(table_mat_test )) / sum(table_mat_test )
print(paste('Accuracy for test', accuracy_Test))


# predicting the model on test data set
predictWithProbabilityDT <- predict(dt_model, newdata = testdata,type = "prob")
aucDT <-auc(testdata$HealthStatus,predictWithProbabilityDT[,2])
aucDT
#https://www.youtube.com/watch?v=qcvAqAH60Yw
#par(pty ="s")

#Sensitivity = TPR, Specificity = FPR




```
## RANDOM FOREST
```{, RANDOMFOREST}
#https://www.blopig.com/blog/2017/04/a-very-basic-introduction-to-random-forests-using-r/
#import the package
library(randomForest)
# Perform training:
rf_classifier = randomForest(HealthStatus ~ ., data=traindata, ntree=100, mtry=2, importance=TRUE)
rf_classifier
varImpPlot(rf_classifier)
# Validation set assessment #1: looking at confusion matrix
prediction_for_table <- predict(rf_classifier,testdata[,-9])
tableRF <- table(Actual=testdata[,9],predicted=prediction_for_table)
tableRF
accuracy_RF <- sum(diag(tableRF)) / sum(tableRF)
print(paste('Accuracy for RandomForest:', accuracy_RF))

#ROC CURVE
#prediction_for_roc_curve <- predict(rf_classifier,testdata[,-9],type="prob")
#forestpred = prediction(prediction_for_roc_curve  [,2], testdata$class)
#forestperf = performance(forestpred, "tpr", "fpr")
#plot(forestperf, main="ROC")
#test.forest = predict(rf_classifier, type = "prob", newdata = testdata)

#https://www.r-bloggers.com/part-3-random-forests-and-model-selection-considerations/
# forestpred = prediction(test.forest[,2], testdata$class)
#forestperf = performance(forestpred, "tpr", "fpr")
#plot(forestperf, main="ROC")
#plot(bagperf, col=2, add=TRUE)
#plot(perf, col=1, add=TRUE)

#legend(0.6, 0.6, c("ctree", "bagging", "rforest"), 1:3)


#auc_prob <-auc(testdata$HealthStatus,prediction.test.forest[,2])
#auc_prob
#par(pty ="s")
#plot(roc(testdata$HealthStatus,prediction.test.forest[,2]),legacy.axes = TRUE,main = "ROC Curve for Random Forest Model",col="#377eb8",lwd = 4,type = "l",xlab = "False Positive Rate", ylab = "True positive Rate",print.auc=TRUE) 


```

```{r, randomforest}
# Random Forest
library(randomForest)
set.seed(222)
ptm <- proc.time() 
rf <- randomForest(HealthStatus~., data=traindata,
                   ntree = 300,
                   mtry = 7,
                   importance = TRUE,
                   proximity = TRUE)
proc.time() - ptm
print(rf)
attributes(rf)
varImpPlot(rf)

# Prediction & Confusion Matrix - train data
library(caret)
p1 <- predict(rf, traindata)
confusionMatrix(p1, traindata$HealthStatus)

# # Prediction & Confusion Matrix - test data
p2 <- predict(rf, testdata)
confusionMatrix(p2, testdata$HealthStatus)
 
# Error rate of Random Forest
plot(rf)
# predicting the model on test data set
predictWithProbabilityRF <- predict(rf, newdata = testdata,type = "prob")
aucRF <-auc(testdata$HealthStatus,predictWithProbabilityRF[,2])
aucRF



```

## NaÃ¯ve Bayes Algorithm
```{r, NaiveBayes}
library(naivebayes)
ptm <- proc.time()
model.naiveBayes <- naive_bayes(traindata$HealthStatus ~., data = traindata)
proc.time() - ptm
object.size(model.naiveBayes)
summary(model.naiveBayes)
names(model.naiveBayes)
model.naiveBayes$prior 
#Predict with NBC
prediction.naiveBayes <- predict(model.naiveBayes, newdata = traindata, type = "class")
confusionMatrix(factor(prediction.naiveBayes), factor(traindata$HealthStatus))

#Predict with NBC
prediction.naiveBayes <- predict(model.naiveBayes, newdata = testdata, type = "class")
confusionMatrix(factor(prediction.naiveBayes), factor(testdata$HealthStatus))

prediction.naiveBayesProbability <- predict(model.naiveBayes, newdata = testdata, type = "prob")
aucNB <-auc(testdata$HealthStatus,prediction.naiveBayesProbability[,2])
aucNB
par(pty ="s")

```


## Gradient Boosting
#Create matrix - One hot Encoding for Factor Variables
```{r, gbm}


# eXtreme Gradient Boosting Model

library(gbm)
#https://www.datatechnotes.com/2018/03/classification-with-gradient-boosting.html
#https://www.datatechnotes.com/2018/03/classification-with-gradient-boosting.html
#https://www.datatechnotes.com/2018/03/classification-with-xgboost-model-in-r.html
ptm <- proc.time()
mod_gbm = gbm(HealthStatus ~.,
              data = traindata,
              distribution = "multinomial",
              cv.folds = 10,
              shrinkage = .01,
              n.minobsinnode = 10,
              n.trees = 200)
proc.time() - ptm
object.size(mod_gbm)
print(mod_gbm)
summary(mod_gbm)
predGBM <- predict.gbm(object = mod_gbm,
                   newdata = testdata,
                   n.trees = 200,
                 
                   type = "response")
 
labels = colnames(predGBM)[apply(predGBM, 1, which.max)]
result = data.frame(testdata$HealthStatus, labels)

#cm = confusionMatrix(testdata$HealthStatus, as.factor(labels))
#print(cm)
confusionMatrix(testdata$HealthStatus, as.factor(labels))


#gbm.roc.area(testdata$HealthStatus, as.factor(labels))
#print(gbm.auc(predGBM, valid = TRUE))

#age,gender,longitude, latitude,chronic_disease_binary,chronic_disease_1, chronic_disease_2,main_symptom, Status)
predictors <- c("age", "gender", "longitude", "latitude","chronic_disease_binary", "chronic_disease_1", "chronic_disease_2", "main_symptom")
response <- "HealthStatus"


```




#GBM using caret package
```{r,gbm Caret}
#https://blog.revolutionanalytics.com/2016/05/using-caret-to-compare-models.html
#https://topepo.github.io/caret/400-training-and-tuning.html
tc = trainControl( summaryFunction=twoClassSummary,	classProbs=TRUE, allowParallel = TRUE)

# Use the expand.grid to specify the search space	
# Note that the default search grid selects multiple values of each tuning parameter
 
grid <- expand.grid(interaction.depth=c(1,2), # Depth of variable interactions
                    n.trees=c(10,20),	        # Num trees to fit
                    shrinkage=c(0.01,0.1),		# Try 2 values for learning rate 
                    n.minobsinnode = 20)
set.seed(1951)  # set the seed
ptm <- proc.time()  
modelGBM = train(HealthStatus ~., data=traindata, method="gbm", metric = "ROC", trControl = tc, tuneGrid=grid, verbose=FALSE)

proc.time() - ptm
names(modelGBM)
pred = predict(modelGBM, testdata)
confusionMatrix(pred, testdata$HealthStatus)
result = data.frame(testdata$HealthStatus, pred)
head(result)
predictWithProbabilityGBM <- predict(modelGBM, newdata = testdata,type = "prob")

aucGBM <-auc(testdata$HealthStatus,predictWithProbabilityGBM[,2])
aucGBM
```
```{r,plots, fig.dim=c(6, 6)}
#https://www.youtube.com/watch?v=qcvAqAH60Yw
par(pty ="s")

plot(roc(testdata$HealthStatus,predictWithProbabilityDT[,2]), legacy.axes = TRUE,main = "ROC Curve for Base Models",col="#377eb8", lwd = 4,type = "l",xlab = "False Positive Rate", ylab = "True positive Rate") 

plot(roc(testdata$HealthStatus,predictWithProbabilityRF[,2]), legacy.axes = TRUE,main = "ROC Curve for Random Forest Model",col="red",lwd = 4,type = "l", add = TRUE) 
plot(roc(testdata$HealthStatus,prediction.naiveBayesProbability[,2]),legacy.axes = TRUE,  col="green",lwd = 4,type = "l",add= TRUE) 
plot(roc(testdata$HealthStatus,predictWithProbabilityGBM[,2]),legacy.axes = TRUE, col="orange",lwd = 4,type = "l", add= TRUE) 



legend("bottomright", c(sprintf("DT (AUC = %.4f )",aucDT),sprintf("RF (AUC = %.4f )",aucRF), sprintf("GBM (AUC = %.4f )",aucGBM), sprintf("NB (AUC = %.4f )",aucNB)), lwd = 2, lty=1, 
    col = c("#377eb8", "red","orange", "green"), xpd=TRUE, bty="n")
    
predictors<-c("gender", "AgeGroup", "longitude", "latitude","main_symptom","chronic_disease_1","chronic_disease_binary")
outcomeName<-'HealthStatus'
ptm <- proc.time()  
fit.rf <- train(traindata[,predictors],traindata[,outcomeName], method="rf", metric = "Accuracy")
proc.time() - ptm
fit.rf

```



```{, execution time}
control <- trainControl(method="repeatedcv", number=10, repeats=3)
seed <- 7
metric <- "Accuracy"
predictors<-c("gender", "AgeGroup", "longitude", "latitude","main_symptom","chronic_disease_1","chronic_disease_binary")
outcomeName<-'HealthStatus'
ptm <- proc.time()  
fit.rpart <- train(traindata[,predictors],traindata[,outcomeName], method="rpart", metric=metric, trControl=control)
proc.time() - ptm
ptm <- proc.time()  
fit.gbm <- train(traindata[,predictors],traindata[,outcomeName],method="gbm", metric=metric, trControl=control)
proc.time() - ptm
ptm <- proc.time()  
fit.rf <- train(traindata[,predictors],traindata[,outcomeName], method="rf", metric=metric, trControl=control)
proc.time() - ptm
ptm <- proc.time()  
fit.nb <- train(traindata[,predictors],traindata[,outcomeName], method="nb", metric=metric, trControl=control)
proc.time() - ptm
results <- resamples(list(rpart = fit.rpart, rf=fit.rf, nb=fit.nb, gbm=fit.gbm))
summary(results)
dotplot(results)
```

